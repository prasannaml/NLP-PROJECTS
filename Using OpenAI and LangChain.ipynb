{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.0.316 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (0.0.316)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (1.4.39)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (2.5.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (8.2.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (0.6.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (1.25.2)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (3.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (1.33)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (2.28.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from langchain==0.0.316) (0.0.69)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (2.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.316) (6.0.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.316) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.316) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.316) (2.1)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.316) (2.14.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.316) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.316) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.316) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.316) (2023.5.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.316) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "# Install the langchain package\n",
    "!pip install langchain==0.0.316\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions==4.8.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (4.8.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the typing_extensions package\n",
    "!pip install typing_extensions==4.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from openai==0.28.1) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from openai==0.28.1) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from openai==0.28.1) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/prasannasundar/anaconda3/lib/python3.10/site-packages (from aiohttp->openai==0.28.1) (4.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os package\n",
    "import os\n",
    "\n",
    "# Import the openai package\n",
    "import openai\n",
    "\n",
    "# Set openai.api_key to the OPENAI_API_KEY environment variable\n",
    "\n",
    "\n",
    "openai.api_key = os.environ[\"OPEN_AI_KEY\"]\n",
    "openai_api_key =os.environ[\"OPEN_AI_KEY\"]\n",
    "#pinecone_key = os.environ[\"PINECONE_KEY\"]\n",
    "#hugging_face_key = os.environ[\"HUGGING_FACE_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the langchain package as lc\n",
    "import langchain as lc\n",
    "\n",
    "# From the langchain.chat_models module, import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# From the langchain.schema module, import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "from langchain.schema import AIMessage,HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas using the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Import plotly.express using the alias px\n",
    "import plotly.express as px\n",
    "\n",
    "# From the IPython.display package, import display and Markdown\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Task 1: Import the Electric Cars Data\n",
    "The electric cars data is contained in a CSV file named electric_cars.csv.\n",
    "\n",
    "Each row in the dataset represents the count of the number of cars registered within a city, for a particular model.\n",
    "\n",
    "The dataset contains the following columns.\n",
    "\n",
    "city (character): The city in which the registered owner resides.\n",
    "county (character): The county in which the registered owner resides.\n",
    "model_year (integer): The model year of the car.\n",
    "make (character): The manufacturer of the car.\n",
    "model (character): The model of the car.\n",
    "electric_vehicle_type (character): Either \"Plug-in Hybrid Electric Vehicle (PHEV)\" or \"Battery Electric Vehicle (BEV)\".\n",
    "n_cars (integer): The count of the number of vehicles registered.\n",
    "Our first step is to import and print the data.\n",
    "\n",
    "Instructions\n",
    "Import the electric cars data to a pandas dataframe.\n",
    "\n",
    "Read the data from electric_cars.csv. Assign to electric_cars.\n",
    "Display a description of the numeric columns of electric_cars.\n",
    "Display a description of the object columns of electric_cars.\n",
    "Print the whole dataset.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'electric_cars.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Read the data from electric_cars.csv. Assign to electric_cars.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m electric_cars\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39melectric_cars.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Display a description of the numeric columns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDescription of numeric columns\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'electric_cars.csv'"
     ]
    }
   ],
   "source": [
    "# Read the data from electric_cars.csv. Assign to electric_cars.\n",
    "\n",
    "electric_cars=pd.read_csv(\"electric_cars.csv\")\n",
    "\n",
    "# Display a description of the numeric columns\n",
    "print(\"Description of numeric columns\\n\")\n",
    "\n",
    "display(electric_cars.describe())\n",
    "\n",
    "# Display a description of the text (object) columns\n",
    "print(\"Description of text columns\\n\")\n",
    "\n",
    "display(electric_cars.describe(include=\"O\"))\n",
    "\n",
    "# Print the whole dataset\n",
    "print(\"The electric cars dataset\\n\")\n",
    "display(electric_cars[electric_cars['county']=='Washington'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message. Assign to system_msg_test.\n",
    "system_msg_test =\"\"\"You are a helpful assistant who understands data science.\n",
    " You write in a clear language that a ten year old can understand.\n",
    " You keep your answers brief.\"\"\"\n",
    "\n",
    "# Define the user message. Assign to user_msg_test.\n",
    "user_msg_test=\"Tell me some uses of GPT for data analysis.\"\n",
    "\n",
    "# Create a message list from the system and user messages. Assign to msgs_test.\n",
    "msgs_test = [\n",
    "    {\"role\": \"system\",\"content\": system_msg_test},\n",
    "    {\"role\":\"user\",\"content\":user_msg_test}\n",
    "]\n",
    "\n",
    "# Send the messages to GPT. Assign to resp_test.\n",
    "resp_test = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=msgs_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The whole response\n",
      "\n",
      "ChatCompletion(id='chatcmpl-8U0tH3W776svJtR9NDJACzy4jOfwW', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content=\"GPT, which stands for Generative Pre-trained Transformer, can be used for data analysis in several ways:\\n\\n1. Text summarization: GPT can help summarize long texts or articles into shorter versions, making it easier to understand the main points.\\n\\n2. Language translation: GPT can be used to automatically translate text from one language to another, making it easier for people who speak different languages to understand each other.\\n\\n3. Sentiment analysis: GPT can analyze text and determine the sentiment, whether it is positive, negative, or neutral. This can be helpful in understanding people's opinions or reactions.\\n\\n4. Question answering: GPT can answer questions based on a given context or knowledge base. It can help find answers to specific queries without needing to read through entire documents.\\n\\n5. Recommendation systems: GPT can analyze past behavior and preferences to recommend products, movies, or music that a person might like. It can help make personalized suggestions.\\n\\nThese are just a few examples of how GPT can be used for data analysis. It has many other applications in natural language processing and understanding.\", role='assistant', function_call=None, tool_calls=None))], created=1702163955, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=220, prompt_tokens=52, total_tokens=272))\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Just the response's content\n",
      "\n",
      "GPT, which stands for Generative Pre-trained Transformer, can be used for data analysis in several ways:\n",
      "\n",
      "1. Text summarization: GPT can help summarize long texts or articles into shorter versions, making it easier to understand the main points.\n",
      "\n",
      "2. Language translation: GPT can be used to automatically translate text from one language to another, making it easier for people who speak different languages to understand each other.\n",
      "\n",
      "3. Sentiment analysis: GPT can analyze text and determine the sentiment, whether it is positive, negative, or neutral. This can be helpful in understanding people's opinions or reactions.\n",
      "\n",
      "4. Question answering: GPT can answer questions based on a given context or knowledge base. It can help find answers to specific queries without needing to read through entire documents.\n",
      "\n",
      "5. Recommendation systems: GPT can analyze past behavior and preferences to recommend products, movies, or music that a person might like. It can help make personalized suggestions.\n",
      "\n",
      "These are just a few examples of how GPT can be used for data analysis. It has many other applications in natural language processing and understanding.\n"
     ]
    }
   ],
   "source": [
    "# Print the whole response\n",
    "print(\"The whole response\\n\")\n",
    "print(resp_test)\n",
    "\n",
    "print(\"\\n\\n----\\n\\n\")\n",
    "\n",
    "# Print just the response's content\n",
    "print(\"Just the response's content\\n\")\n",
    "print(resp_test.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A description of the dataset\n",
    "dataset_description = \"\"\"\n",
    "You have a dataset about electric cars registered in Washington state, USA in 2020. It is available as a pandas DataFrame named `electric_cars`.\n",
    "\n",
    "Each row in the dataset represents the count of the number of cars registered within a city, for a particular model.\n",
    "\n",
    "The dataset contains the following columns.\n",
    "\n",
    "- `city` (character): The city in which the registered owner resides.\n",
    "- `county` (character): The county in which the registered owner resides.\n",
    "- `model_year` (integer): The [model year](https://en.wikipedia.org/wiki/Model_year#United_States_and_Canada) of the car.\n",
    "- `make` (character): The manufacturer of the car.\n",
    "- `model` (character): The model of the car.\n",
    "- `electric_vehicle_type` (character): Either \"Plug-in Hybrid Electric Vehicle (PHEV)\" or \"Battery Electric Vehicle (BEV)\".\n",
    "- `n_cars` (integer): The count of the number of vehicles registered.\n",
    "\"\"\"\n",
    "\n",
    "# Create a task for the AI. Assign to suggest_questions.\n",
    "suggest_questions = \"Suggest some questions for exploratory analysis with this dataset.\"\n",
    "\n",
    "# Concatenate the dataset description and the request. Assign to msgs_suggest_questions.\n",
    "msgs_suggest_questions=[SystemMessage(content=\"You are an expert data analyst\"),\n",
    "                       HumanMessage(content=f\"{dataset_description}     {suggest_questions}\") \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are an expert data analyst', additional_kwargs={}),\n",
       " HumanMessage(content='\\nYou have a dataset about electric cars registered in Washington state, USA in 2020. It is available as a pandas DataFrame named `electric_cars`.\\n\\nEach row in the dataset represents the count of the number of cars registered within a city, for a particular model.\\n\\nThe dataset contains the following columns.\\n\\n- `city` (character): The city in which the registered owner resides.\\n- `county` (character): The county in which the registered owner resides.\\n- `model_year` (integer): The [model year](https://en.wikipedia.org/wiki/Model_year#United_States_and_Canada) of the car.\\n- `make` (character): The manufacturer of the car.\\n- `model` (character): The model of the car.\\n- `electric_vehicle_type` (character): Either \"Plug-in Hybrid Electric Vehicle (PHEV)\" or \"Battery Electric Vehicle (BEV)\".\\n- `n_cars` (integer): The count of the number of vehicles registered.\\n     Suggest some questions for exploratory analysis with this dataset.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs_suggest_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create a ChatOpenAI object. Assign to chat.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m chat \u001b[39m=\u001b[39m ChatOpenAI(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Pass your message to GPT. Assign to rsps_suggest_questions.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m rsps_suggest_questions \u001b[39m=\u001b[39m chat(messages\u001b[39m=\u001b[39mmsgs_suggest_questions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/langchain/load/serializable.py:75\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39m\"\"\"List of attribute names that should be included in the serialized kwargs.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[39m    These attributes must be accepted by the constructor.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m {}\n\u001b[0;32m---> 75\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlc_id\u001b[39m(\u001b[39mcls\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m     77\u001b[0m     \u001b[39m\"\"\"A unique identifier for this class for serialization purposes.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[1;32m     79\u001b[0m \u001b[39m    The unique identifier is a list of strings that describes the path\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m    to the object.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39m*\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_lc_namespace(), \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "# Create a ChatOpenAI object. Assign to chat.\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",)\n",
    "\n",
    "# Pass your message to GPT. Assign to rsps_suggest_questions.\n",
    "rsps_suggest_questions = chat(messages=msgs_suggest_questions)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Print the response\n",
    "print(\"The whole response\\n\")\n",
    "print(rsps_suggest_questions)\n",
    "\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Print just the response's content\n",
    "print(\"Just the response's content\\n\")\n",
    "\n",
    "print(rsps_suggest_questions.content)\n",
    "print(\"\\n----\\n\")\n",
    "\n",
    "# Print the type of the response\n",
    "print(\"The type of the response\\n\")\n",
    "print(type(rsps_suggest_questions))  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rsps_suggest_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Append the response and a new message to the previous messages. \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Assign to msgs_python_top_models.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m msgs_python_top_models\u001b[39m=\u001b[39m msgs_suggest_questions \u001b[39m+\u001b[39m [\n\u001b[0;32m----> 4\u001b[0m     rsps_suggest_questions,\n\u001b[1;32m      5\u001b[0m     HumanMessage(content\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrite Python Code to find the top make and model combinations of electric car in Washington state.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[39m# Pass your message to GPT. Assign to rsps_python_top_models.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m rsps_python_top_models \u001b[39m=\u001b[39mchat(msgs_python_top_models)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rsps_suggest_questions' is not defined"
     ]
    }
   ],
   "source": [
    "# Append the response and a new message to the previous messages. \n",
    "# Assign to msgs_python_top_models.\n",
    "msgs_python_top_models= msgs_suggest_questions + [\n",
    "    rsps_suggest_questions,\n",
    "    HumanMessage(content=\"Write Python Code to find the top make and model combinations of electric car in Washington state.\")\n",
    "]\n",
    "\n",
    "# Pass your message to GPT. Assign to rsps_python_top_models.\n",
    "rsps_python_top_models =chat(msgs_python_top_models)\n",
    "\n",
    "# Display the response's Markdown content\n",
    "display(Markdown(rsps_python_top_models.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the code generated by GPT and run it\n",
    "# Filter the dataset for electric cars in Washington state\n",
    "washington_cars = electric_cars[electric_cars['county'] == 'Washington']\n",
    "\n",
    "#we wanted in state of washington which is all of dataset,not county of washington\n",
    "print(washington_cars)\n",
    "\n",
    "# Group the data by make and model and calculate the total number of registrations\n",
    "grouped_cars = electric_cars.groupby(['make', 'model']).sum('n_cars')\n",
    "print(grouped_cars)\n",
    "# Sort the data in descending order based on the number of registrations\n",
    "sorted_cars = grouped_cars.sort_values(by='n_cars', ascending=False)\n",
    "# Get the top make and model combinations\n",
    "top_make_model_combinations = sorted_cars.head()\n",
    "\n",
    "# Print the top make and model combinations\n",
    "print(top_make_model_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new OpenAI chat object with temperature set to zero. Assign to chat0.\n",
    "#temperature 0 to 2 range, zero min randomness,langchain default 0.7,open ai default 1\n",
    "\n",
    "chat0 = ChatOpenAI(temperature= 0,openai_api_key=os.environ[\"OPEN_AI_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask GPT for code for a bar plot, as detailed in the instructions\n",
    "msgs_python_plot = msgs_python_top_models + [rsps_python_top_models,HumanMessage(content=\"Write python code with plotly express to to draw a bar plot of the total count of electric cars by model year, with bars colored by electric vehicle type.\")\n",
    "                                            \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "resp_python_plot = chat0(msgs_python_plot)\n",
    "\n",
    "\n",
    "display(Markdown(resp_python_plot.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call GPT again with the same message list and display the response\n",
    "\n",
    "\n",
    "resp_python_plot_1 = chat0(msgs_python_plot)\n",
    "\n",
    "\n",
    "display(Markdown(resp_python_plot_1.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the code generated by GPT and run it\n",
    "import plotly.express as px\n",
    "\n",
    "# Group the data by model year and electric vehicle type and calculate the total count of electric cars\n",
    "grouped_cars = electric_cars.groupby(['model_year', 'electric_vehicle_type']).sum('n_cars').reset_index()\n",
    "\n",
    "# Draw the bar plot using Plotly Express\n",
    "fig = px.bar(grouped_cars, x='model_year', y='n_cars', color='electric_vehicle_type',\n",
    "             title='Total Count of Electric Cars by Model Year',\n",
    "             labels={'model_year': 'Model Year', 'n_cars': 'Count of Electric Cars'},\n",
    "             color_discrete_map={'Plug-in Hybrid Electric Vehicle (PHEV)': 'blue',\n",
    "                                 'Battery Electric Vehicle (BEV)': 'green'})\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
