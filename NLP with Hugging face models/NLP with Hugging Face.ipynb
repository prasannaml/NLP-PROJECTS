{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the other required packages and modules.\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import semantic_search\n",
    "\n",
    "\n",
    "# From the IPython.display package, import display and Markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "netflix = pd.read_csv(\"/Users/prasannasundar/Projects/Using OpenAI and Langchain/NLP and AI /data/netflix_dataset.csv\") # parse column as datetime for visualization  \n",
    "print(runway.info())\n",
    "\n",
    "print(runway.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre Processing\n",
    "\n",
    "#remove forward slash \n",
    "\n",
    "runway['review_text_cleaned']=runway['review_text'].str.replace(r\"\\/\",\"\")\n",
    "\n",
    "#remove punctuation\n",
    "runway['review_text_cleaned']=runway['review_text_cleaned'].str.translate(string.punctuation)\n",
    "\n",
    "\n",
    "#remove digits\n",
    "runway['review_text_cleaned']=runway['review_text_cleaned'].str.replace(r\"\\d+\",\"\")\n",
    "\n",
    "#remove running spaces\n",
    "\n",
    "runway['review_text_cleaned']=runway['review_text_cleaned'].str.replace(r\"\\s{2,}\",\"\")  #removing 2 or more spaces\n",
    "#make text lowercase\n",
    "runway['review_text_cleaned']=runway['review_text_cleaned'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runway['review_text_cleaned'][4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert based model for sentiment analysis\n",
    "senti_model = \"distilbert-base-uncased-finetuned-sst-2-english\" \n",
    "\n",
    "\n",
    "#instantiate new pipeline object\n",
    "\n",
    "sentimentAnalysis = pipeline(\"sentiment-analysis\",model=senti_model)\n",
    "\n",
    "# Run on cleaned review text\n",
    "\n",
    "\n",
    "sent_analysis_output = sentimentAnalysis(list(runway[\"review_text_cleaned\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of Sentiment Score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#parse output as sentiment category label and score\n",
    "runway['clean_sentiment_category'] = [s['label'] for s in sent_analysis_output]\n",
    "runway['clean_sentiment_score'] = [s['score'] for s in sent_analysis_output]\n",
    "\n",
    "\n",
    "\n",
    "sns.histplot(data=runway,x=\"clean_sentiment_score\",bins=20)\n",
    "\n",
    "plt.suptitle(\"Distribution of sentiment score\")\n",
    "\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "\n",
    "plt.ylabel(\"Count of reviews\")\n",
    "\n",
    "\n",
    "plt.title(\"For Clean Review Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insight\n",
    "# Most reviews are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze reviews by year\n",
    "\n",
    "chart_data = runway.groupby(['year', 'clean_sentiment_category'], as_index=False)['user_id'].count()\n",
    "chart_data.columns = ['year', 'clean_sentiment_category', 'cnt']\n",
    "\n",
    "# Create a bar plot showing the count of reviews for each sentiment category over the years.\n",
    "sns.barplot(data=chart_data, x=\"year\", y=\"cnt\", hue=\"clean_sentiment_category\", errorbar = None)\n",
    "plt.title(\"Sentiment between 2016 - 2023\")\n",
    "plt.xlabel(\"Review Year\")\n",
    "plt.ylabel(\"Count of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews have increased every year until 2022. The % of positive reviews also has been on an increeasing trend. 2021 was a game changer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if unprocessed review data makes any difference for the sentiment category\n",
    "\n",
    "\n",
    "\n",
    "sent_analysis_output2 = sentimentAnalysis(list(runway[\"review_text\"]))\n",
    "\n",
    "\n",
    "#parse output as sentiment category label and score\n",
    "runway['clean_sentiment_category2'] = [s['label'] for s in sent_analysis_output2]\n",
    "runway['clean_sentiment_score2'] = [s['score'] for s in sent_analysis_output2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "display( pd.crosstab(runway['clean_sentiment_category2'],runway['clean_sentiment_category2']))\n",
    "\n",
    "\n",
    "display( pd.crosstab(runway['clean_sentiment_category'],runway['clean_sentiment_category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' insight: we got almost same sentiment category from unprocessed review data.\n",
    "this is because the transformers model BERT  uses self attention and gains context from sequences in texts, This allows the models to  work well with text as is and unstructured,\n",
    "For this particular application we can use unprocessed data '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text embeddings\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# Instantiate a new SentenceTransformer object.\n",
    "model = SentenceTransformer(model_id)\n",
    "\n",
    "# Generate the embeddings for the \"rented for\" column.\n",
    "embeddings = model.encode(list(runway[\"rented for\"]))\n",
    "\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define query\n",
    "query = \"a gorgeous and flattering dress\"\n",
    "\n",
    "# Embed query\n",
    "query_emb = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Calculate similarity between query and item embeddings\n",
    "hits = semantic_search(query_emb, embeddings, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print top similar items\n",
    "for x in x[0]:\n",
    "    id = x['corpus_id']\n",
    "    display(\n",
    "        \"ITEM ID: \", runway.iloc[id]['item_id'], \n",
    "        \"; RENTED FOR: \", runway.iloc[id]['rented for'],\n",
    "        \"; REVIEW\", runway.iloc[id]['review_text'],\n",
    "        \"; clean_sentiment_category\", runway.iloc[id]['clean_sentiment_category'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
